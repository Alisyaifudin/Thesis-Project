{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vaex\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file path\n",
    "file = \"1rv.hdf5\"\n",
    "data = vaex.open(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide into multiple RAs for stability\n",
    "ras = np.linspace(0,360, 361).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to select the BEST parameter, not optimized tho, but works\n",
    "\n",
    "# TypeScript-like style type definitions\n",
    "# Input\n",
    "## pars: {\n",
    "##   value: number\n",
    "##   error: {\n",
    "##     lower: number\n",
    "##     upper: number\n",
    "##   } | number // upper and lower error OR just singgle number\n",
    "##   cat: string // catalog name\n",
    "## }[] // parameter values\n",
    "## index: number // row index\n",
    "\n",
    "# Output: Array\n",
    "## par: {\n",
    "##   value: number\n",
    "##   error: {\n",
    "##     lower: number\n",
    "##     upper: number\n",
    "##   } // best upper and lower error\n",
    "##   symmetric: boolean // if lower == upper\n",
    "##   cat: string // best catalog name\n",
    "## }\n",
    "\n",
    "NaN = {'value': np.nan, 'error': {'lower': np.nan, 'upper': np.nan}, 'symmetric': np.nan , 'cat': np.nan}\n",
    "\n",
    "def select_best(pars, index):\n",
    "    pars = np.array(pars)\n",
    "    if len(pars) == 0: return NaN\n",
    "    elif len(pars) == 1:\n",
    "        if ('lower' in pars[0]['error']) and ('upper' in pars[0]['error']):\n",
    "            if np.isnan(pars[0]['error']['lower']):\n",
    "                pars[0]['symmetric'] = np.nan\n",
    "            else:\n",
    "                pars[0]['symmetric'] = pars[0]['error']['lower'] == pars[0]['error']['upper']\n",
    "        elif np.isnan(pars[0]['error']):\n",
    "            pars[0]['symmetric'] = np.nan\n",
    "        elif (type(pars[0]['error']) == float) or (type(pars[0]['error']) == int):\n",
    "            pars[0]['symmetric'] = True\n",
    "        if np.isnan(pars[0]['value']):\n",
    "            pars[0] = NaN\n",
    "        return pars[0]\n",
    "    else:\n",
    "        mask = []\n",
    "        for i, par in enumerate(pars):\n",
    "            if(type(par['error']) == float) or (type(par['error']) == int):\n",
    "                mask.append(par['error'] > 0)\n",
    "                pars[i]['error'] = {'lower': par['error'], 'upper': par['error']}\n",
    "            elif (type(par['error']) == dict):\n",
    "                if('lower' not in par['error']) or ('upper' not in par['error']): \n",
    "                    raise TypeError('lower and/or upper keys dont exist')\n",
    "                mask.append(par['error']['lower'] > 0 and par['error']['upper'] > 0)\n",
    "        pars = pars[mask]\n",
    "        errors = np.array(list(map(lambda x: (x['error']['lower'] + x['error']['upper'])/2, pars)))\n",
    "        values = np.array(list(map(lambda x: x['value'], pars)))\n",
    "        if len(pars) == 0: return NaN\n",
    "        elif len(pars) == 1:\n",
    "            pars[0]['symmetric'] = pars[0]['error']['lower'] == pars[0]['error']['upper']\n",
    "            return pars[0]\n",
    "        elif len(rvs) == 2:\n",
    "            i = np.argmin(errors)\n",
    "            pars[i]['symmetric'] = pars[i]['error']['lower'] == pars[i]['error']['upper']\n",
    "            return pars[i]\n",
    "        else:\n",
    "            avg = np.average(values, weights=1/errors)\n",
    "            selected_pars = []\n",
    "            for par in pars:\n",
    "                if (par['value'] + par['error']['upper'] > avg) and (par['value'] - par['error']['lower'] < avg):\n",
    "                    selected_pars.append(par)\n",
    "            if (len(selected_pars) == 0):\n",
    "                i = np.argmin(errors)\n",
    "                pars[i]['symmetric'] = pars[i]['error']['lower'] == pars[i]['error']['upper']\n",
    "                return pars[i]\n",
    "            else:\n",
    "                errors = np.array(list(map(lambda x: (x['error']['lower'] + x['error']['upper'])/2, selected_pars)))\n",
    "                i = np.argmin(errors)\n",
    "                selected_pars[i]['symmetric'] = selected_pars[i]['error']['lower'] == selected_pars[i]['error']['upper']\n",
    "                return selected_pars[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract which columns should be used\n",
    "\n",
    "# par_cols: {\n",
    "#   value: string\n",
    "#   error?: {\n",
    "#     upper: string\n",
    "#     lower: string\n",
    "#   } | string\n",
    "#   cat: string\n",
    "# }[]\n",
    "# row: pandas.core.series.Series\n",
    "def extract_pars(par_cols, row):\n",
    "    pars = []\n",
    "    for col in par_cols:\n",
    "        par = {}\n",
    "        par['value'] = row[col['value']]\n",
    "        if type(col['error']) == dict:\n",
    "            if ('lower' not in col['error']) or ('upper' not in col['error']):\n",
    "                raise TypeError('lower and/or upper does not exist in error dict')\n",
    "            par['error'] = {'lower': par['value'] - row[col['error']['lower']] , 'upper': row[col['error']['upper']] - par['value']}\n",
    "        elif (type(col['error']) == str):\n",
    "            par['error'] = row[col['error']]\n",
    "        else:\n",
    "            par['error'] = np.nan\n",
    "        par['cat'] = col['cat']\n",
    "        pars.append(par)\n",
    "    return pars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "removed_columns = [ 'rv_gaia', 'e_rv_gaia', 'teff_gspphot', 'teff_gspphot_lower', 'teff_gspphot_upper',\n",
    "                     'logg_gspphot', 'logg_gspphot_lower', 'logg_gspphot_upper', 'mh_gspphot', 'mh_gspphot_lower',\n",
    "                     'mh_gspphot_upper', 'mh_gspspec', 'mh_gspspec_lower', 'mh_gspspec_upper', 'alphafe_gspspec',\n",
    "                     'alphafe_gspspec_lower', 'alphafe_gspspec_upper', 'fem_gspspec', 'fem_gspspec_lower',\n",
    "                     'fem_gspspec_upper','rv_rave', 'e_rv_rave', 'teff_rave', 'logg_rave', 'mh_rave',\n",
    "                     'alphafe_rave', 'rv_galah', 'e_rv_galah', 'feh_galah', 'alphafe_galah', 'teff_galah',\n",
    "                     'e_teff_galah', 'logg_galah', 'e_logg_galah', 'teff_lamost', 'e_teff_lamost',\n",
    "                     'logg_lamost', 'e_logg_lamost', 'feh_lamost', 'e_feh_lamost', 'rv_lamost',\n",
    "                     'e_rv_lamost', 'alpham_lamost', 'e_alpham_lamost', 'rv_apogee', 'e_rv_apogee',\n",
    "                     'teff_apogee', 'e_teff_apogee', 'logg_apogee', 'e_logg_apogee', 'mh_apogee',\n",
    "                     'e_mh_apogee', 'feh_apogee', 'e_feh_apogee', 'alpham_apogee', 'e_alpham_apogee']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cols initiation\n",
    "rv_cols = [\n",
    "    {\n",
    "        'value': 'rv_gaia', \n",
    "        'error': 'e_rv_gaia', \n",
    "        'cat': 'gaia'\n",
    "    }, \n",
    "    {\n",
    "        'value': 'rv_rave', \n",
    "        'error': 'e_rv_rave', \n",
    "        'cat': 'rave'\n",
    "    },\n",
    "    {\n",
    "        'value': 'rv_apogee', \n",
    "        'error': 'e_rv_apogee', \n",
    "        'cat': 'apogee'\n",
    "    },\n",
    "    {\n",
    "        'value': 'rv_lamost', \n",
    "        'error': 'e_rv_lamost', \n",
    "        'cat': 'lamost'\n",
    "    },\n",
    "    {\n",
    "        'value': 'rv_galah', \n",
    "        'error': 'e_rv_galah', \n",
    "        'cat': 'galah'\n",
    "    }\n",
    "]\n",
    "\n",
    "teff_cols = [\n",
    "    {\n",
    "        'value': 'teff_gspphot', \n",
    "        'error': {\n",
    "            'upper': 'teff_gspphot_upper',\n",
    "            'lower': 'teff_gspphot_lower'\n",
    "        }, \n",
    "        'cat': 'gspphot'\n",
    "    }, \n",
    "    {\n",
    "        'value': 'teff_rave', \n",
    "        'error': np.nan, \n",
    "        'cat': 'rave'\n",
    "    },\n",
    "    {\n",
    "        'value': 'teff_apogee', \n",
    "        'error': 'e_teff_apogee', \n",
    "        'cat': 'apogee'\n",
    "    },\n",
    "    {\n",
    "        'value': 'teff_lamost', \n",
    "        'error': 'e_teff_lamost', \n",
    "        'cat': 'lamost'\n",
    "    },\n",
    "    {\n",
    "        'value': 'teff_galah', \n",
    "        'error': 'e_teff_galah', \n",
    "        'cat': 'galah'\n",
    "    }\n",
    "]\n",
    "\n",
    "logg_cols = [\n",
    "    {\n",
    "        'value': 'logg_gspphot', \n",
    "        'error': {\n",
    "            'upper': 'logg_gspphot_upper',\n",
    "            'lower': 'logg_gspphot_lower'\n",
    "        }, \n",
    "        'cat': 'gspphot'\n",
    "    }, \n",
    "    {\n",
    "        'value': 'logg_rave', \n",
    "        'error': np.nan, \n",
    "        'cat': 'rave'\n",
    "    },\n",
    "    {\n",
    "        'value': 'logg_apogee', \n",
    "        'error': 'e_logg_apogee', \n",
    "        'cat': 'apogee'\n",
    "    },\n",
    "    {\n",
    "        'value': 'logg_lamost', \n",
    "        'error': 'e_logg_lamost', \n",
    "        'cat': 'lamost'\n",
    "    },\n",
    "    {\n",
    "        'value': 'logg_galah', \n",
    "        'error': 'e_logg_galah', \n",
    "        'cat': 'galah'\n",
    "    }\n",
    "]\n",
    "\n",
    "mh_cols = [\n",
    "    {\n",
    "        'value': 'mh_gspphot', \n",
    "        'error': {\n",
    "            'upper': 'mh_gspphot_upper',\n",
    "            'lower': 'mh_gspphot_lower'\n",
    "        }, \n",
    "        'cat': 'gspphot'\n",
    "    },\n",
    "    {\n",
    "        'value': 'mh_gspspec', \n",
    "        'error': {\n",
    "            'upper': 'mh_gspspec_upper',\n",
    "            'lower': 'mh_gspspec_lower'\n",
    "        }, \n",
    "        'cat': 'gspspec'\n",
    "    },\n",
    "    {\n",
    "        'value': 'mh_rave', \n",
    "        'error': np.nan, \n",
    "        'cat': 'rave'\n",
    "    },\n",
    "    {\n",
    "        'value': 'mh_apogee', \n",
    "        'error': 'e_mh_apogee', \n",
    "        'cat': 'apogee'\n",
    "    }\n",
    "]\n",
    "\n",
    "alphafe_cols = [\n",
    "    {\n",
    "        'value': 'alphafe_gspspec', \n",
    "        'error': {\n",
    "            'upper': 'alphafe_gspspec_upper',\n",
    "            'lower': 'alphafe_gspspec_lower'\n",
    "        }, \n",
    "        'cat': 'gspspec'\n",
    "    },\n",
    "    {\n",
    "        'value': 'alphafe_rave', \n",
    "        'error': np.nan, \n",
    "        'cat': 'rave'\n",
    "    },\n",
    "    {\n",
    "        'value': 'alphafe_galah', \n",
    "        'error': np.nan, \n",
    "        'cat': 'galah'\n",
    "    }\n",
    "]\n",
    "\n",
    "fem_cols = [\n",
    "    {\n",
    "        'value': 'fem_gspspec', \n",
    "        'error': {\n",
    "            'upper': 'fem_gspspec_upper',\n",
    "            'lower': 'fem_gspspec_lower'\n",
    "        }, \n",
    "        'cat': 'gspspec'\n",
    "    }\n",
    "]\n",
    "\n",
    "feh_cols = [\n",
    "    {\n",
    "        'value': 'feh_galah', \n",
    "        'error': np.nan, \n",
    "        'cat': 'galah'\n",
    "    },\n",
    "    {\n",
    "        'value': 'feh_lamost', \n",
    "        'error': 'e_feh_lamost', \n",
    "        'cat': 'lamost'\n",
    "    },\n",
    "    {\n",
    "        'value': 'feh_apogee', \n",
    "        'error': 'e_feh_apogee', \n",
    "        'cat': 'apogee'\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the operation!\n",
    "df_com = []\n",
    "for i, (ra0, ra1) in enumerate(zip(ras[:-1], ras[1:])):\n",
    "    # if ra0 <= 69: continue\n",
    "    rvs = []\n",
    "    teffs = []\n",
    "    loggs = []\n",
    "    mhs = []\n",
    "    alphafes = []\n",
    "    fems = []\n",
    "    fehs = []\n",
    "\n",
    "    data_filtered = data.filter(data.ra > ra0).filter(data.ra <= ra1)\n",
    "    df = data_filtered.to_pandas_df()\n",
    "    t0 = time()\n",
    "    for index, row in df.iterrows():\n",
    "        # rv\n",
    "        rv = extract_pars(rv_cols, row)\n",
    "        rv_best = select_best(rv, index)\n",
    "        rvs.append(rv_best)\n",
    "        # teff\n",
    "        teff = extract_pars(teff_cols, row)\n",
    "        teff_best = select_best(teff, index)\n",
    "        teffs.append(teff_best)\n",
    "        # logg\n",
    "        logg = extract_pars(logg_cols, row)\n",
    "        logg_best = select_best(logg, index)\n",
    "        loggs.append(logg_best)\n",
    "        # mh\n",
    "        mh = extract_pars(mh_cols, row)\n",
    "        mh_best = select_best(mh, index)\n",
    "        mhs.append(mh_best)\n",
    "        # alphafe\n",
    "        alphafe = extract_pars(alphafe_cols, row)\n",
    "        alphafe_best = select_best(alphafe, index)\n",
    "        alphafes.append(alphafe_best)\n",
    "        # fem\n",
    "        fem = extract_pars(fem_cols, row)\n",
    "        fem_best = select_best(fem, index)\n",
    "        fems.append(fem_best)\n",
    "        # feh\n",
    "        feh = extract_pars(feh_cols, row)\n",
    "        feh_best = select_best(feh, index)\n",
    "        fehs.append(feh_best)\n",
    "        \n",
    "    # rv    \n",
    "    df['rv'] = list(map(lambda x: x['value'], rvs))\n",
    "    df['e_rv'] = list(map(lambda x: x['error']['lower'], rvs))\n",
    "    df['rv_cat'] = list(map(lambda x: x['cat'], rvs))\n",
    "    # teff   \n",
    "    df['teff'] = list(map(lambda x: x['value'], teffs))\n",
    "    df['e_teff_lower'] = list(map(lambda x: x['error']['lower'], teffs))\n",
    "    df['e_teff_upper'] = list(map(lambda x: x['error']['upper'], teffs))\n",
    "    df['teff_symmetric'] = np.array(list(map(lambda x: x['symmetric'], teffs)))\n",
    "    df['teff_cat'] = list(map(lambda x: x['cat'], teffs))\n",
    "    # logg\n",
    "    df['logg'] = list(map(lambda x: x['value'], loggs))\n",
    "    df['e_logg_lower'] = list(map(lambda x: x['error']['lower'], loggs))\n",
    "    df['e_logg_upper'] = list(map(lambda x: x['error']['upper'], loggs))\n",
    "    df['logg_symmetric'] = np.array(list(map(lambda x: x['symmetric'], loggs)))\n",
    "    df['logg_cat'] = list(map(lambda x: x['cat'], loggs))\n",
    "    # mh\n",
    "    df['mh'] = list(map(lambda x: x['value'], mhs))\n",
    "    df['e_mh_lower'] = list(map(lambda x: x['error']['lower'], mhs))\n",
    "    df['e_mh_upper'] = list(map(lambda x: x['error']['upper'], mhs))\n",
    "    df['mh_symmetric'] = np.array(list(map(lambda x: x['symmetric'], mhs)))\n",
    "    df['mh_cat'] = list(map(lambda x: x['cat'], mhs))\n",
    "    # alphafe\n",
    "    df['alphafe'] = list(map(lambda x: x['value'], alphafes))\n",
    "    df['e_alphafe_lower'] = list(map(lambda x: x['error']['lower'], alphafes))\n",
    "    df['e_alphafe_upper'] = list(map(lambda x: x['error']['upper'], alphafes))\n",
    "    df['alphafe_symmetric'] = np.array(list(map(lambda x: x['symmetric'], alphafes)))\n",
    "    df['alphafe_cat'] = list(map(lambda x: x['cat'], alphafes))\n",
    "    # fem\n",
    "    df['fem'] = list(map(lambda x: x['value'], fems))\n",
    "    df['e_fem_lower'] = list(map(lambda x: x['error']['lower'], fems))\n",
    "    df['e_fem_upper'] = list(map(lambda x: x['error']['upper'], fems))\n",
    "    df['fem_symmetric'] = np.array(list(map(lambda x: x['symmetric'], fems)))\n",
    "    df['fem_cat'] = list(map(lambda x: x['cat'], fems))\n",
    "    # feh\n",
    "    df['feh'] = list(map(lambda x: x['value'], fems))\n",
    "    df['e_feh_lower'] = list(map(lambda x: x['error']['lower'], fehs))\n",
    "    df['e_feh_upper'] = list(map(lambda x: x['error']['upper'], fehs))\n",
    "    df['feh_symmetric'] = np.array(list(map(lambda x: x['symmetric'], fehs)))\n",
    "    df['feh_cat'] = list(map(lambda x: x['cat'], fehs))\n",
    "    df.drop(labels=removed_columns,axis=1, inplace=True)\n",
    "    if len(df_com) == 0:\n",
    "        df_com = vaex.from_pandas(df)\n",
    "    else:\n",
    "        df_com = df_com.concat(vaex.from_pandas(df))\n",
    "    t1 = time()\n",
    "    print(f\"saved {ra0:03d}-{ra1:03d} | {round(t1-t0, 2)}s\", end=\" | \")\n",
    "    if ra1 % 60 == 0:\n",
    "        # export every 60deg interval\n",
    "        df_com.export(f\"rv/rv-{(ra1-60):03d}-{ra1:03d}.hdf5\", progress=True)\n",
    "        df_com = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you want tp see rv distribution by which catalog it was choosen, run this\n",
    "df_com['rv_cat'].value_counts().plot(kind='bar')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
